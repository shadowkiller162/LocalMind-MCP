#!/usr/bin/env python3
"""
Ollama å®¢æˆ¶ç«¯æ‰‹å‹•æ¸¬è©¦è…³æœ¬

æ­¤è…³æœ¬éœ€è¦ Ollama æœå‹™æ­£åœ¨é‹è¡Œæ‰èƒ½åŸ·è¡Œå®Œæ•´æ¸¬è©¦ã€‚
å¦‚æœ Ollama æœªé‹è¡Œï¼Œéƒ¨åˆ†æ¸¬è©¦æœƒå¤±æ•—ï¼Œé€™æ˜¯æ­£å¸¸ç¾è±¡ã€‚

ä½¿ç”¨æ–¹æ³•:
docker compose exec django python mcp/tests/manual_test_ollama.py
"""

import asyncio
import sys
from mcp.llm.client import OllamaClient
from mcp.llm.manager import ModelManager
from mcp.llm.types import ChatMessage, GenerateRequest, ChatRequest


async def test_ollama_client_manual():
    """æ¸¬è©¦ Ollama å®¢æˆ¶ç«¯åŸºæœ¬åŠŸèƒ½"""
    print("=== Ollama å®¢æˆ¶ç«¯æ‰‹å‹•æ¸¬è©¦ ===")
    
    client = OllamaClient()
    
    # 1. æ¸¬è©¦å¥åº·æª¢æŸ¥
    print("1. æ¸¬è©¦ Ollama æœå‹™å¥åº·æª¢æŸ¥...")
    try:
        health = await client.health_check()
        print(f"   å¥åº·æª¢æŸ¥çµæœ: {'âœ… æ­£å¸¸' if health else 'âŒ ç•°å¸¸'}")
        
        if not health:
            print("   âš ï¸  Ollama æœå‹™æœªé‹è¡Œï¼Œè·³éå¾ŒçºŒæ¸¬è©¦")
            return False
    except Exception as e:
        print(f"   âŒ å¥åº·æª¢æŸ¥å¤±æ•—: {e}")
        print("   âš ï¸  è«‹ç¢ºä¿ Ollama æœå‹™æ­£åœ¨é‹è¡Œ")
        return False
    
    # 2. æ¸¬è©¦æ¨¡å‹åˆ—è¡¨
    print("\n2. æ¸¬è©¦æ¨¡å‹åˆ—è¡¨...")
    try:
        async with client:
            models = await client.list_models()
            print(f"   æ‰¾åˆ° {len(models)} å€‹æ¨¡å‹:")
            for model in models[:3]:  # åªé¡¯ç¤ºå‰3å€‹
                print(f"     - {model.name} (å¤§å°: {model.size} bytes)")
    except Exception as e:
        print(f"   âŒ ç²å–æ¨¡å‹åˆ—è¡¨å¤±æ•—: {e}")
    
    # 3. æ¸¬è©¦æ–‡æœ¬ç”Ÿæˆï¼ˆéœ€è¦æ¨¡å‹ï¼‰
    print("\n3. æ¸¬è©¦æ–‡æœ¬ç”Ÿæˆ...")
    try:
        async with client:
            # å˜—è©¦ä½¿ç”¨å¸¸è¦‹çš„å°æ¨¡å‹
            test_models = ["llama2", "llama3.2", "qwen2", "phi3"]
            
            for model_name in test_models:
                try:
                    print(f"   å˜—è©¦æ¨¡å‹: {model_name}")
                    request = GenerateRequest(
                        model=model_name,
                        prompt="Hello, how are you? Please respond in one sentence.",
                    )
                    
                    response = await client.generate(request)
                    print(f"   âœ… ç”ŸæˆæˆåŠŸ:")
                    print(f"     æ¨¡å‹: {response.model}")
                    print(f"     å›æ‡‰: {response.content[:100]}...")
                    break
                except Exception as e:
                    print(f"   âŒ æ¨¡å‹ {model_name} ç”Ÿæˆå¤±æ•—: {e}")
                    continue
            else:
                print("   âš ï¸  æ²’æœ‰å¯ç”¨çš„æ¨¡å‹é€²è¡Œæ¸¬è©¦")
    except Exception as e:
        print(f"   âŒ æ–‡æœ¬ç”Ÿæˆæ¸¬è©¦å¤±æ•—: {e}")
    
    return True


async def test_model_manager_manual():
    """æ¸¬è©¦æ¨¡å‹ç®¡ç†å™¨åŠŸèƒ½"""
    print("\n=== æ¨¡å‹ç®¡ç†å™¨æ‰‹å‹•æ¸¬è©¦ ===")
    
    manager = ModelManager()
    
    # 1. æ¸¬è©¦åˆå§‹åŒ–
    print("1. æ¸¬è©¦ç®¡ç†å™¨åˆå§‹åŒ–...")
    try:
        await manager.initialize()
        print("   âœ… åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"   âŒ åˆå§‹åŒ–å¤±æ•—: {e}")
        return False
    
    # 2. æ¸¬è©¦å¥åº·æª¢æŸ¥
    print("\n2. æ¸¬è©¦ç®¡ç†å™¨å¥åº·æª¢æŸ¥...")
    try:
        health = await manager.health_check()
        print(f"   å¥åº·æª¢æŸ¥çµæœ: {'âœ… æ­£å¸¸' if health else 'âŒ ç•°å¸¸'}")
    except Exception as e:
        print(f"   âŒ å¥åº·æª¢æŸ¥å¤±æ•—: {e}")
    
    # 3. æ¸¬è©¦æ¨¡å‹åˆ—è¡¨
    print("\n3. æ¸¬è©¦æ¨¡å‹åˆ—è¡¨...")
    try:
        models = await manager.list_models()
        print(f"   ç®¡ç†å™¨ä¸­æœ‰ {len(models)} å€‹æ¨¡å‹")
        
        if models:
            print("   å‰3å€‹æ¨¡å‹:")
            for model in models[:3]:
                print(f"     - {model.name} (ç‹€æ…‹: {model.status.value})")
    except Exception as e:
        print(f"   âŒ ç²å–æ¨¡å‹åˆ—è¡¨å¤±æ•—: {e}")
    
    # 4. æ¸¬è©¦é è¨­æ¨¡å‹
    print("\n4. æ¸¬è©¦é è¨­æ¨¡å‹...")
    try:
        default_model = await manager.get_default_model()
        print(f"   é è¨­æ¨¡å‹: {default_model}")
    except Exception as e:
        print(f"   âŒ ç²å–é è¨­æ¨¡å‹å¤±æ•—: {e}")
    
    # 5. æ¸¬è©¦èŠå¤©åŠŸèƒ½ï¼ˆå¦‚æœæœ‰å¯ç”¨æ¨¡å‹ï¼‰
    print("\n5. æ¸¬è©¦èŠå¤©åŠŸèƒ½...")
    try:
        models = await manager.list_models()
        if models:
            test_model = models[0].name
            messages = [
                ChatMessage(role="user", content="Hello! Please say hi back in one word.")
            ]
            
            response = await manager.chat(test_model, messages)
            print(f"   âœ… èŠå¤©æˆåŠŸ:")
            print(f"     æ¨¡å‹: {response.model}")
            print(f"     å›æ‡‰: {response.content}")
        else:
            print("   âš ï¸  æ²’æœ‰å¯ç”¨æ¨¡å‹é€²è¡ŒèŠå¤©æ¸¬è©¦")
    except Exception as e:
        print(f"   âŒ èŠå¤©æ¸¬è©¦å¤±æ•—: {e}")
    
    # 6. æ¸…ç†
    print("\n6. æ¸…ç†ç®¡ç†å™¨...")
    try:
        await manager.cleanup()
        print("   âœ… æ¸…ç†æˆåŠŸ")
    except Exception as e:
        print(f"   âŒ æ¸…ç†å¤±æ•—: {e}")
    
    return True


async def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    print("ğŸš€ é–‹å§‹ MCP Ollama æ•´åˆæ‰‹å‹•æ¸¬è©¦")
    print("=" * 50)
    
    # æ¸¬è©¦ Ollama å®¢æˆ¶ç«¯
    client_success = await test_ollama_client_manual()
    
    if client_success:
        # æ¸¬è©¦æ¨¡å‹ç®¡ç†å™¨
        await test_model_manager_manual()
    
    print("\n" + "=" * 50)
    print("ğŸ æ¸¬è©¦å®Œæˆ")
    
    if not client_success:
        print("\nğŸ’¡ å¦‚è¦å®Œæ•´æ¸¬è©¦ï¼Œè«‹ç¢ºä¿:")
        print("   1. Ollama æœå‹™æ­£åœ¨é‹è¡Œ (ollama serve)")
        print("   2. è‡³å°‘å®‰è£ä¸€å€‹æ¨¡å‹ (ollama pull llama2)")
        print("   3. ç¶²è·¯é€£æ¥æ­£å¸¸")


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nâš ï¸  æ¸¬è©¦è¢«ç”¨æˆ¶ä¸­æ–·")
        sys.exit(0)
    except Exception as e:
        print(f"\nâŒ æ¸¬è©¦åŸ·è¡Œå¤±æ•—: {e}")
        sys.exit(1)