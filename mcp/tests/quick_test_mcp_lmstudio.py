#!/usr/bin/env python3
"""
MCP-LMStudio å¿«é€Ÿæ•´åˆæ¸¬è©¦

å¿«é€Ÿé©—è­‰ MCP ç³»çµ±èˆ‡ LM Studio çš„åŸºæœ¬é€£æ¥å’Œå°è©±åŠŸèƒ½
"""

import asyncio
import sys
from mcp.llm.unified_manager import UnifiedModelManager, LLMServiceType
from mcp.llm.types import ChatMessage


async def quick_test():
    """å¿«é€Ÿæ¸¬è©¦æ ¸å¿ƒåŠŸèƒ½"""
    print("ğŸ” MCP-LMStudio å¿«é€Ÿæ•´åˆæ¸¬è©¦")
    print("=" * 50)
    
    manager = UnifiedModelManager(preferred_service=LLMServiceType.AUTO)
    
    try:
        # 1. åˆå§‹åŒ–
        print("1. åˆå§‹åŒ–ç®¡ç†å™¨...")
        await manager.initialize()
        print("   âœ… æˆåŠŸ")
        
        # 2. æª¢æŸ¥æœå‹™
        print("\n2. æª¢æŸ¥å¯ç”¨æœå‹™...")
        services = await manager.get_available_services()
        print(f"   LM Studio: {'âœ…' if services.get('lmstudio') else 'âŒ'}")
        print(f"   Ollama: {'âœ…' if services.get('ollama') else 'âŒ'}")
        
        if not services.get('lmstudio'):
            print("   âŒ LM Studio ä¸å¯ç”¨")
            return False
        
        # 3. ç²å–æ¨è–¦æ¨¡å‹
        print("\n3. ç²å–æ¨è–¦æ¨¡å‹...")
        model = await manager.get_recommended_model()
        print(f"   æ¨è–¦æ¨¡å‹: {model}")
        
        # 4. ç°¡å–®å°è©±æ¸¬è©¦
        print("\n4. æ¸¬è©¦å°è©±...")
        messages = [
            ChatMessage(role="user", content="Say 'Hello from MCP!' in response.")
        ]
        
        response = await manager.chat(model, messages)
        print(f"   æ¨¡å‹å›æ‡‰: {response.content[:100]}...")
        
        print(f"\nâœ… æ¸¬è©¦å®Œæˆï¼MCP æˆåŠŸèˆ‡ LM Studio æ•´åˆ")
        return True
        
    except Exception as e:
        print(f"\nâŒ æ¸¬è©¦å¤±æ•—: {e}")
        return False
    finally:
        await manager.cleanup()


if __name__ == "__main__":
    success = asyncio.run(quick_test())
    sys.exit(0 if success else 1)